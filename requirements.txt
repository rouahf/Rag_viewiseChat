import streamlit as st  # Streamlit pour créer l'interface utilisateur de l'app web
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter  # divise un texte en morceaux plus petits
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import google.generativeai as genai
from langchain.vectorstores import FAISS  # pour recherche
from langchain_google_genai import ChatGoogleGenerativeAI  # générer des réponses à partir de l'API de Google Generative AI
from langchain.chains.question_answering import load_qa_chain 
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import pandas as pd
import json
import os
import uuid
from langchain.document_loaders import UnstructuredURLLoader
from langchain.memory import SimpleMemory  # Importer SimpleMemory


class VectorStoreManager:  # gestion du stockage et le chargement des vecteurs
    def __init__(self):
        self.vector_store_folder = None  # utilisé pour stocker les fichiers vectoriels
        
    def create_vector_store(self, text_chunks):
        unique_id = str(uuid.uuid4())
        self.vector_store_folder = f"faiss_index_{unique_id}"
        os.makedirs(self.vector_store_folder, exist_ok=True)
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)
        vector_store.save_local(self.vector_store_folder)
        return self.vector_store_folder

    def load_vector_store(self, folder):
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        return FAISS.load_local(folder, embeddings, allow_dangerous_deserialization=True)


class EmbeddingManager:
    def __init__(self):
        load_dotenv()
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment variables.")
        genai.configure(api_key=api_key)

    def process_files_and_url(self, uploaded_files, url):
        raw_text = self.get_all_text_from_files(uploaded_files)
        if url:
            raw_text += self.get_url_text(url)
        text_chunks = self.get_text_chunks(raw_text)
        return text_chunks

    def get_all_text_from_files(self, uploaded_files):
        raw_text = ""
        pdf_docs = [file for file in uploaded_files if file.name.endswith('.pdf')]
        csv_docs = [file for file in uploaded_files if file.name.endswith('.csv')]
        txt_docs = [file for file in uploaded_files if file.name.endswith('.txt')]
        xls_docs = [file for file in uploaded_files if file.name.endswith('.xls')]
        json_docs = [file for file in uploaded_files if file.name.endswith('.json')]

        if pdf_docs:
            raw_text += self.get_pdf_text(pdf_docs)
        if csv_docs:
            raw_text += self.get_csv_text(csv_docs)
        if txt_docs:
            raw_text += self.get_txt_text(txt_docs)
        if xls_docs:
            raw_text += self.get_xls_text(xls_docs)
        if json_docs:
            raw_text += self.get_json_text(json_docs)

        return raw_text

    def get_pdf_text(self, pdf_docs):
        text = ""
        for pdf in pdf_docs:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                text += page.extract_text()
        return text

    def get_csv_text(self, csv_docs):
        text = ""
        for csv in csv_docs:
            df = pd.read_csv(csv)
            text += df.to_string(index=False)
        return text

    def get_txt_text(self, txt_docs):
        text = ""
        for txt in txt_docs:
            text += txt.read().decode("utf-8")
        return text

    def get_xls_text(self, xls_docs):
        text = ""
        for xls in xls_docs:
            df = pd.read_excel(xls)
            text += df.to_string(index=False)
        return text

    def get_json_text(self, json_docs):
        text = ""
        for json_file in json_docs:
            data = json.load(json_file)
            text += json.dumps(data, indent=2)
        return text

    def get_url_text(self, url):
        loader = UnstructuredURLLoader(urls=[url])
        documents = loader.load()
        text = "\n".join([doc.page_content for doc in documents])
        return text

    def get_text_chunks(self, text):
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)
        chunks = text_splitter.split_text(text)
        return chunks


class ChatbotApp:
    def __init__(self):
        self.vector_store_manager = VectorStoreManager()
        self.embedding_manager = EmbeddingManager()
        self.memory = SimpleMemory()  # Initialiser la mémoire
        self.setup_streamlit()

    def setup_streamlit(self):
        st.set_page_config("Chat with Files")
        st.header("Chat with Files and URLs using Gemini")

        if 'conversation' not in st.session_state:
            st.session_state.conversation = []

        with st.sidebar:
            st.title("Configuration:")
            self.chatbot_name = st.text_input("Chatbot Name")

            role_options = ["Customer Support", "Sales Assistant", "Technical Support", "HR Assistant"]
            self.role = st.selectbox("Chatbot Role and Objective", role_options)

            self.company_name = st.text_input("Company Name")

            activity_domain_options = ["Tourism", "Healthcare", "Transport", "Telecom", "Sport", "Finance"]
            self.activity_domain = st.selectbox("Activity Domain", activity_domain_options)

            instructions_options = ["Provide detailed answers", "Be concise", "Use friendly language", "Be formal"]
            self.instructions = st.selectbox("Instructions for the Chatbot", instructions_options)

            self.phone_number = st.text_input("Phone Number")
            self.social_media = st.text_input("Social Media (e.g., Twitter, LinkedIn)")

            st.title("Menu:")
            self.uploaded_files = st.file_uploader(
                "Upload your Files and Click on the Submit & Process Button",
                accept_multiple_files=True,
                type=['pdf', 'csv', 'txt', 'xls', 'json']
            )

            self.url = st.text_input("Enter a URL to process")

            if st.button("Submit & Process"):
                self.process_files_and_url()

        user_question = st.text_input("Ask a Question from the Files or URLs")
        if user_question:
            self.handle_user_input(user_question)

        self.display_conversation()

    def process_files_and_url(self):
        with st.spinner("Processing..."):
            text_chunks = self.embedding_manager.process_files_and_url(self.uploaded_files, self.url)
            if text_chunks:
                vector_store_folder = self.vector_store_manager.create_vector_store(text_chunks)
                st.session_state.vector_store_folder = vector_store_folder
                st.success("Processing completed successfully!")
            else:
                st.error("No valid text found in the provided files and URL.")

    def get_conversational_chain(self, chatbot_name, role, company_name, activity_domain, instructions, phone_number, social_media):
        prompt_template = f"""
        Your name is {chatbot_name}, a chatbot for {company_name} operating in the {activity_domain} domain.
        Your role is {role}.
        Here are your instructions: {instructions}.
        Your contact phone number is {phone_number}.
        Your social media profile is {social_media}.
        Answer the question as detailed as possible from the provided context and about your details 
        
        Context:\n {{context}}\n
        Question: \n{{question}}\n

        Answer:
        """
        model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3)
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        
        # Création de la chaîne avec le paramètre de mémoire
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt, memory=self.memory)
        
        return chain

    def handle_user_input(self, user_question):
        if 'vector_store_folder' not in st.session_state:
            st.error("Please upload and process files or URLs first.")
            return

        vector_store_folder = st.session_state.vector_store_folder
        new_db = self.vector_store_manager.load_vector_store(vector_store_folder)
        docs = new_db.similarity_search(user_question)
        chain = self.get_conversational_chain(
            self.chatbot_name, self.role, self.company_name, self.activity_domain, self.instructions, self.phone_number, self.social_media
        )
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        st.session_state.conversation.append({"question": user_question, "answer": response["output_text"]})

    def display_conversation(self):
        st.subheader("Conversation History")
        for i, convo in enumerate(st.session_state.conversation):
            cols = st.columns(2)
            with cols[0]:
                st.write(f"**Question {i+1}:**")
                st.write(convo['question'])
            with cols[1]:
                st.write(f"**Answer {i+1}:**")
                st.write(convo['answer'])


if __name__ == "__main__":
    ChatbotApp()
